{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Col1 Col2\n",
      "1    3   30\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Create the first DataFrame\n",
    "df1 = pd.DataFrame({'Col1': [\"1\", \"2\", \"3\", \"90u08\"], 'Col2': [\"10\", \"20\", \"30\", \"999\"], 'Col3': ['A', 'B', 'C', \"d\"]})\n",
    "\n",
    "# Create the second DataFrame\n",
    "df2 = pd.DataFrame({'Col1': [\"2\", \"3\", \"4\", \"kkjk\"], 'Col2': [\"20 4050\", \"30\", \"40\", \"fsdsgfd\"]})\n",
    "\n",
    "# Iterate over the rows of df2 and check if each value in 'Col2' is present in df1['Col2']\n",
    "merged_df = df2[df2[\"Col2\"].isin(df1[\"Col2\"])]\n",
    "\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gooz7\n",
      "['CL6-634', 'L6-635', 'L6-636', 'L6-637', 'L6-638', 'L6-639', 'L6-640', 'L6-M-716']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "string1=\"10, 12\"\n",
    "string2=\"B-15, 16, 17\"\n",
    "string3 = \"G C 331\"\n",
    "string4= \"M/ 18&19\"\n",
    "string5= \"Ma/ 20&G 32\"\n",
    "string6 = \"B-FB5-1 TO B-FB5-8\"\n",
    "string7= \"B-13, B17, T-5-15\"\n",
    "string8 = \" B3-39 TO B3-63 B3-65 TO B3-66 B3-68 TO B3-94 P1-15, P1-16, P5-18, B3-1 TO B3-16\"\n",
    "string8_1 = \"G-26 TO G-29\"\n",
    "string9 = \"B/A-157, C/D-67 , P2/A-13\"\n",
    "\n",
    "\n",
    "\n",
    "string=\"CL6-634,L6-635,L6-636,L6-637,L6-638,L6-639,L6-640,L6-M-716\"\n",
    "\n",
    "# 10, 12 | 10 12\n",
    "if re.match(r\"^(\\d+)\\s?-?,?\\s?&?(\\d+\\s?,?-?&?\\s?)*$\", string):\n",
    "    print(\"gooz1\")\n",
    "    match = re.findall(r\"\\d+\", string)\n",
    "    print(match)\n",
    "\n",
    "# B-15, 16, 17\n",
    "elif re.match(r\"^(\\w+-?\\s?)(\\d+\\s?-?,?.?\\s?)*$\", string):\n",
    "    print(\"gooz2\")\n",
    "    match1 = re.findall(r\"^(\\w+)\", string)\n",
    "    match2 = re.findall(r\"\\d+\", string)\n",
    "    match = []\n",
    "    for st in match2:\n",
    "        match.append(match1[0] + \"-\" + st)\n",
    "    print(match)\n",
    "\n",
    "# \"G C 331\"\n",
    "elif re.match(r\"^\\w(\\s\\w)*\\d+$\", string):\n",
    "    print(\"gooz3\")\n",
    "    match1 = re.findall(r\"([a-zA-Z])\", string)\n",
    "    match2 = re.findall(r\"(\\d+)\", string)\n",
    "    match = []\n",
    "    for P_al in match1:\n",
    "        for P_no in match2:\n",
    "            match.append(P_al + \"-\" + P_no)\n",
    "    print(match)\n",
    "\n",
    "# M/ 18&19\n",
    "elif re.match(r\"^(\\w+\\s?/\\s?)(\\d+\\s?&?)(\\d+\\s?&?)*$\", string):\n",
    "    print(\"gooz4\")\n",
    "    match1 = re.findall(r\"(\\w+)\", string)\n",
    "    match2 = re.findall(r\"\\d+\", string)\n",
    "    match = []\n",
    "    for st in match2:\n",
    "        match.append(match1[0] + \"-\" + st)\n",
    "    print(match)\n",
    "\n",
    "# \"Ma/ 20&G 32\"\n",
    "elif re.match(r\"^(\\w+\\s?/\\s?)(\\d+\\s?&)((\\w+\\s?-?\\d+)(\\s?&?-?))*$\", string):\n",
    "    print(\"gooz5\")\n",
    "    match1 = re.findall(r\"([a-zA-Z]+)\", string)\n",
    "    match2 = re.findall(r\"\\d+\", string)\n",
    "    match = []\n",
    "    for i in range(len(match2)):\n",
    "        match.append(match1[i] + \"-\" + match2[i])\n",
    "    print(match)\n",
    "\n",
    "#\"B-FB5-1 TO B-FB5-8\"\n",
    "elif re.match(r\"\\w+-\\w+-\\d+\\s?(?i:to)\\s?\\w+-\\w+-\\d+\", string):\n",
    "    print(\"gooz6\")\n",
    "    match1 = re.findall(r\"(\\w+-\\w+)-(\\d+)\", string)\n",
    "    F = match1[0][0]\n",
    "    start = int(match1[0][1])\n",
    "    end = int(match1[1][1])\n",
    "    match = []\n",
    "    for j in range(start, end + 1):\n",
    "        match.append(F + \"-\" + str(j))\n",
    "    print(match)\n",
    "    \n",
    "\n",
    "\n",
    "# B-13, B17, T-5-15    G-26 TO G-29    G-028,G-T01     CL6-669  6-M-721\n",
    "elif re.match(r\"((\\w+-?\\s?\\w+-?\\s?\\w+)\\s?-?,?&?.?\\s?)*$\", string):\n",
    "    print(\"gooz7\")\n",
    "    if \"TO\" in string:\n",
    "        match1 = re.findall(r\"(\\w+-?\\s?\\w+)\\s?-?\\s?((?i:to))\\s?(\\w+-?\\s?\\w+)\\s?-?\", string)\n",
    "        F, start = match1[0][0].split(\"-\")\n",
    "        _, end = match1[0][2].split(\"-\")\n",
    "        start = int(start)\n",
    "        end = int(end)\n",
    "        match = []\n",
    "        for j in range(start, end + 1):\n",
    "            match.append(F + \"-\" + str(j))\n",
    "        print(match)\n",
    "    else:\n",
    "        match =re.findall(r\"\\w+-?\\s?\\w+-?\\s?\\w+\\b\", string)\n",
    "        print(match)\n",
    "\n",
    "# B3-39 TO B3-63 B3-65 TO B3-66 B3-68 TO B3-94 P1-15,P1-16, P5-18,  B3-1 TO B3-16\n",
    "elif re.match(r\"^(\\s?\\w+-?\\s?\\w+\\s?-?)((?i:to))?(\\s?\\w+-?\\s?\\w+\\s?-?)((\\s?\\w+-?\\s?\\w+\\s?-?)(,?\\s?)((?i:to))?(\\s?\\w+-?\\s?\\w+\\s?-?)?)*\", string):\n",
    "    print(\"gooz8\")\n",
    "    match1 = [x[0] for x in re.findall(r\"(\\w+-?\\s?\\w+)\\s?-?\\s?((?i:to))\", string)]\n",
    "    match2 = [x[1] for x in re.findall(r\"((?i:to))\\s?(\\w+-?\\s?\\w+)\\s?-?\", string)]\n",
    "    match = [x for x in re.findall(r\"\\b\\w+-?\\d+-\\d+\\b\", string) if ((x not in match1) and (x not in match2))]\n",
    "    for i in range(len(match1)):\n",
    "        F, start = match1[i].split(\"-\")\n",
    "        _, end = match2[i].split(\"-\")\n",
    "        start = int(start)\n",
    "        end = int(end)\n",
    "        for j in range(start, end + 1):\n",
    "            match.append(F + \"-\" + str(j))\n",
    "\n",
    "    print(match)\n",
    "\n",
    "\n",
    "# B/A-157, C/D-67\n",
    "elif re.match(r\"(\\w+/\\w+-?\\s?\\d)(\\s?&?,?\\s?)*\", string):\n",
    "    print(\"gooz9\")\n",
    "    match1 = re.findall(r\"\\w+/[a-zA-Z]\", string)\n",
    "    match2 = re.findall(r\"\\w+-(\\d+)\", string)\n",
    "    print(match1)\n",
    "    print(match2)\n",
    "    match = set()\n",
    "    for P_al in match1:\n",
    "        alpha = P_al.split(\"/\")\n",
    "        for j in alpha:\n",
    "            for k in match2:\n",
    "                match.add(j + \"-\" + k)\n",
    "\n",
    "    match = list(match)\n",
    "    print(match)\n",
    "\n",
    "#NAN, Attached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1151/3858435929.py:7: DtypeWarning: Columns (12,13,22,23,25,26,35,36) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(DATA_dir / filename, chunksize=batch_size):\n",
      "/tmp/ipykernel_1151/3858435929.py:7: DtypeWarning: Columns (7,10,12,13,25,26,29,36,38,39,41,42) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(DATA_dir / filename, chunksize=batch_size):\n",
      "/tmp/ipykernel_1151/3858435929.py:7: DtypeWarning: Columns (3,4,7,16,18,19,22,23,44,45) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(DATA_dir / filename, chunksize=batch_size):\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def batch_data_loader(filename, batch_size=1000000):\n",
    "    df = pd.DataFrame()\n",
    "    DATA_dir = Path(\"./src/Data/\")\n",
    "    for chunk in pd.read_csv(DATA_dir / filename, chunksize=batch_size):\n",
    "        df = pd.concat([df, chunk])\n",
    "\n",
    "    return df\n",
    "\n",
    "df_trans_pulse = batch_data_loader(filename=\"Transactions.csv\")\n",
    "df_trans_dld = batch_data_loader(filename=\"transactions-2023-09-05.csv\")\n",
    "df_unit = batch_data_loader(filename=\"Units.csv\")\n",
    "df_rent = batch_data_loader(filename=\"Rent_Contracts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['contract_id', 'contract_reg_type_id', 'contract_reg_type_ar',\n",
       "       'contract_reg_type_en', 'contract_start_date', 'contract_end_date',\n",
       "       'contract_amount', 'annual_amount', 'no_of_prop', 'line_number',\n",
       "       'is_free_hold', 'ejari_bus_property_type_id',\n",
       "       'ejari_bus_property_type_ar', 'ejari_bus_property_type_en',\n",
       "       'ejari_property_type_id', 'ejari_property_type_en',\n",
       "       'ejari_property_type_ar', 'ejari_property_sub_type_id',\n",
       "       'ejari_property_sub_type_en', 'ejari_property_sub_type_ar',\n",
       "       'property_usage_en', 'property_usage_ar', 'project_number',\n",
       "       'project_name_ar', 'project_name_en', 'master_project_ar',\n",
       "       'master_project_en', 'area_id', 'area_name_ar', 'area_name_en',\n",
       "       'actual_area', 'nearest_landmark_ar', 'nearest_landmark_en',\n",
       "       'nearest_metro_ar', 'nearest_metro_en', 'nearest_mall_ar',\n",
       "       'nearest_mall_en', 'tenant_type_id', 'tenant_type_ar',\n",
       "       'tenant_type_en'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rent.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_pulse_building = df_trans_pulse[\"building_name_en\"].str.lower().unique()\n",
    "trans_pulse_area = df_trans_pulse[\"area_name_en\"].str.lower().unique()\n",
    "trans_pulse_land = df_trans_pulse[\"nearest_landmark_en\"].str.lower().unique()\n",
    "trans_pulse_mal = df_trans_pulse[\"nearest_mall_en\"].str.lower().unique()\n",
    "trans_pulse_metro = df_trans_pulse[\"nearest_metro_en\"].str.lower().unique()\n",
    "\n",
    "trans_dld_area = df_trans_dld[\"Area\"].str.lower().unique()\n",
    "trans_dld_land = df_trans_dld[\"Nearest Landmark\"].str.lower().unique()\n",
    "trans_dld_mal = df_trans_dld[\"Nearest Mall\"].str.lower().unique()\n",
    "trans_dld_metro = df_trans_dld[\"Nearest Metro\"].str.lower().unique()\n",
    "\n",
    "unit_area = df_unit[\"area_name_en\"].str.lower().unique()\n",
    "\n",
    "rent_area = df_rent[\"area_name_en\"].str.lower().unique()\n",
    "rent_land = df_rent[\"nearest_landmark_en\"].str.lower().unique()\n",
    "rent_mal = df_rent[\"nearest_mall_en\"].str.lower().unique()\n",
    "rent_metro = df_rent[\"nearest_metro_en\"].str.lower().unique()\n",
    "\n",
    "\n",
    "# df = pd.DataFrame()\n",
    "\n",
    "# columns_list =[trans_pulse_building, trans_pulse_area, trans_pulse_land,\n",
    "#                 trans_pulse_mal, trans_pulse_metro, trans_dld_area,\n",
    "#                   trans_dld_land, trans_dld_mal, trans_dld_metro,\n",
    "#                   unit_area, rent_area,\n",
    "#                   rent_mal, rent_metro\n",
    "#                   ]\n",
    "# for index, col in enumerate(columns_list):\n",
    "#     try:\n",
    "#         print(f\"{len(col)}\")\n",
    "#         df1 = pd.DataFrame(col)\n",
    "#         df = pd.concat([df, df1], axis=1)\n",
    "#     except:\n",
    "#         columns_list[index]\n",
    "\n",
    "# data = {\"trans_pulse_building\": trans_pulse_building,\n",
    "#                   \"trans_pulse_area\": trans_pulse_area,\n",
    "#                   \"trans_pulse_land\": trans_pulse_land,\n",
    "#                   \"trans_pulse_mal\": trans_pulse_mal,\n",
    "#                   \"trans_pulse_metro\": trans_pulse_metro,\n",
    "#                   \"trans_dld_area\": trans_dld_area,\n",
    "#                   \"trans_dld_land\": trans_dld_land,\n",
    "#                   \"trans_dld_mal\": trans_dld_mal,\n",
    "#                   \"trans_dld_metro\": trans_dld_metro,\n",
    "#                   \"unit_area\": unit_area,\n",
    "#                   \"rent_area\": rent_area,\n",
    "#                   \"rent_land\": rent_land,\n",
    "#                   \"rent_mal\": rent_mal,\n",
    "#                   \"rent_metro\": rent_metro\n",
    "#                   }\n",
    "\n",
    "\n",
    "# df = pd.DataFrame({k: pd.Series(v) for k, v in data.items()})\n",
    "\n",
    "# df.to_excel(\"uniqe_building_and_areas.xlsx\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "363"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "areas = np.append(trans_pulse_area, trans_dld_area)\n",
    "areas = np.append(areas, unit_area)\n",
    "areas = np.append(areas, rent_area)\n",
    "\n",
    "df = pd.DataFrame({\"Area_Names\": areas})\n",
    "df = pd.DataFrame(df[\"Area_Names\"].unique())\n",
    "\n",
    "df.to_csv(\"Area_names.csv\", index=False)\n",
    "\n",
    "len(set(areas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3231\n",
      "1083828\n",
      "3231\n"
     ]
    }
   ],
   "source": [
    "df_trans_pulse[\"building_name_en\"] = df_trans_pulse[\"building_name_en\"].str.lower()\n",
    "print(len(df_trans_pulse[\"building_name_en\"].unique()))\n",
    "\n",
    "# Step 2: Check for duplicates\n",
    "duplicates = df_trans_pulse.duplicated(subset=[\"building_name_en\"], keep=\"last\")\n",
    "\n",
    "print(len(duplicates))\n",
    "\n",
    "# Step 3: Invert the mask to get unique rows\n",
    "\n",
    "unique_rows = ~duplicates\n",
    "\n",
    "# Step 4: Filter the dataframe\n",
    "result = df_trans_pulse[unique_rows][[\"building_name_en\", \"area_name_en\", \"nearest_landmark_en\", \"nearest_metro_en\", \"nearest_mall_en\"]]\n",
    "# print(result)\n",
    "\n",
    "print(len(result))\n",
    "\n",
    "result.to_csv(\"Building_names.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uniqes of trans_pulse = 255\n",
      "uniqes of trans_DLD = 225\n",
      "uniqes of units = 225\n",
      "uniqes of rent = 214\n"
     ]
    }
   ],
   "source": [
    "print(f\"uniqes of trans_pulse = {len(trans_pulse_area.str.lower().unique())}\")\n",
    "print(f\"uniqes of trans_DLD = {len(trans_dld_area.str.lower().unique())}\")\n",
    "print(f\"uniqes of units = {len(unit_area.str.lower().unique())}\")\n",
    "print(f\"uniqes of rent = {len(rent_area.str.lower().unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "unique1 = [x for x in rent_area.str.lower().unique() if x not in trans_pulse_area.str.lower().unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"1\": [1, 3, 4],\n",
    "                   \"2\": [1, 4]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
